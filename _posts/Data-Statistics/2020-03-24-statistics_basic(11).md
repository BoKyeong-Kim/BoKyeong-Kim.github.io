---
layout: post
title: 기초통계(11)
subtitle: < 예측모델 >
feature-img: "assets/img/sample_feature_img_2.png"
sitemap :
changefreq : daily
priority : 1.0
categories : [Data/Statistics]
tags: [데이터, 통계, 예측모델, 예측오차]
---

- 예측모델 성능평가
	- 예측오차
	- 교차유효성

<br>

--------------------------------
### 예측오차
#### 개념
- 오차 : 실제값과 예측값 차이의 정도
- 예측오차 : 예측 분석 시 발생하는, 예측값과 실제값의 차이

<br>

### 예측모델 종류별 적합도 평가 방법
#### 예측기법
- 독립변수와 종속변수 사이의 관계를 찾아 종속변수의 값을 예측하는 모형을 만드는 데이터 분석방법

<br>


#### 예측모델 
- 예측 기법을 사용하여 생성된 종속변수 값을 예측하는 값을 찾기 위한 함수식

<br>


#### 예측모델 종류
- 회귀분석
	- 독립변수가 종속변수에 영향을 미치는지 검증하는 분석방법
- 의사결정나무
	- 목표와 상황과의 상호관련성을 나타내어 해당 상호관련성을 규칙화하고, 나무 구조로 도표화하여 분류와 예측을 수행하는 분석방법
- 신경망 기법 
	- 인간의 뇌 신경망(시냅스 결합)을 본떠 만든 알고리즘을 사용한 예측기법
- 사례 기반 추론
	- 과거 사례들의 결과를 기반으로 새로운 사례의 결과를 예측하는 기법


<br>


#### 모델 적합도 평가 방법
![size_main]({{ site.baseurl }}/assets/img/
prediction_model(1).png)

<br>

- 회귀모델 : 모델의 잔차검정
	- 잔차란 모델에 의해 추정된 종속변수의 값과, 실제 관찰된 종속변수 값과의 차이
- 1) 등분산성 : 기울기가 0에 가깝고, 산점도를 그렸을 때, 데이터 점들이 패턴 없이 무작위 분포를 나타내야함
- 2) 정규성 : 잔차가 정규분포를 따르는지 확인함
- 3) 독립성 
	- 0에 가까울수록 양의 자기상관이 있음 - 회귀모형 부적함
	- 2에 가까울수록 자기상관이 거의 없음 - 회귀식에 잔차가 존재하지 않음
	- 4에 가까울수록 음의 자기상관이 있음 - 부적합

<br>

#### 회귀 모델의 적합도 지수
- 회귀모델의 적합도 평가에는 대표적으로 사용되는 잔차 검정외에도, 아래와 같은 지수들이 판단 기준으로 사용됨
- $$R^2$$(결정계수)
	- 설명력의 지표
	- 추정된 회귀모형이 데이터를 얼마나 잘 설명하도록 추정되었는지를 나타냄
	- 결정계수가 1에 가까울수록 설명력이 좋다고 판단함
	- 결정계수가 0에 가까울수록 설명력이 낮다고 판단함
- F검정통계량
	- 모형의 유의성 지표
	- 회귀모형의 통계적 유의성을 검정하기 위한 검정통계량
- T검정통계량
	- 회귀 계수의 유의성 지표

<br>

-----------------------------
### 교차유효성
#### 개념
- 주어진 데이터의 일부를 학습시켜 모델을 생성하고, 나머지 일부(비학습 데이터)는 모델을 검증하는데 사용하는 것
- 연구결과에 대한 타당성을, 해당 연구에 사용하지 않은 표본(sample)으로 평가해보는 타당화 방법을 지칭

<br>

#### 필요성
- 과적합(overfitting)을 방지하기 위해 교차유효성 검사를 함
	- 과적합 : 모델을 생성하는데 사용한 데이터가 지나치게 해당 모델에 적합하게 학습된 나머지, 비학습 데이터 혹은 향후에 만들어질 모델에 대해 예측력이 떨어지거나, 성능이 좋지 않은 상태

![size_main]({{ site.baseurl }}/assets/img/
Cross-Validation(1).png)
	

<br>

#### 종류
![size_main]({{ site.baseurl }}/assets/img/
Cross-Validation(2).png)


<br>

#### Cross-Validation
- 1 ~ n개의 데이터를 무작위로 n등분하여, 데이터를 Training/Validation으로 나눈 다음 교차하여 확인하는 방법
- 장점
	- 구현법이 간단
	- 결과값을 추출하는데 걸리는 시간이 짧음
- 단점
	- 표본의 수와 무작위 추출에 결과값이 크게 영향을 받아 결과값이 불안정해 질 수 있음
	- 테스팅 횟수가 적어, 모형을 정확히 평가하기 힘든 경우가 많음
	- 대표성에 제약이 따름

<br>

#### LOOCV
- 데이터 3개 중 하나만을 Validation set으로 두고, 나머지를 Training set으로 모델에 적합시키는 방법
- 자료가 n개인 경우, 위 과정을 n번 반복 후 결과치들의 평균을 도출하여 사용함
- 장점
	- 결과값이 비교적 정확함
	- n-1개의 데이터를 이용하여 결과값을 구하므로, 비편향에 근사하는 성질을 띠기 때문
- 단점
	- 계산량이 많음
	- 시간이 많이 걸림
	- 각 라인별 MSE(평균제곱오차)가 높은 상관관계를 가지기 쉬움(N번 반복되는 과정의 학습 데이터들이 유사하기 때문)
	- 분산이 큼

<br>

#### K-Fold Cross-Validation
- 과다한 연산량을 줄여주는 방법
- 데이터를 랜덤으로 섞은 후 K등분 한 것 중 하나를 Validation set으로 사용하는 방법
- 장점
	- LOOCV보다 적은 연산량으로 빠른 시간내에 결과값을 구할 수 있음(k-1개의 데이터를 이용하여 결과값을 구하기 때문)
	- LOOCV와 결과값에 크게 차이가 없음
- 단점
	- 데이터셋을 랜덤하게 섞음으로 인해 변동성이 수반됨
	- k번의 연산 반복으로 이를 상쇄하므로 큰 문제는 없음




-------------

* 출처 : 통계 기반 데이터 분석 강의 [https://e-koreatech.step.or.kr/page/lms/learning?m1=home%25&course_id=100168%25](https://e-koreatech.step.or.kr/page/lms/learning?m1=home%25&course_id=100168%25)






