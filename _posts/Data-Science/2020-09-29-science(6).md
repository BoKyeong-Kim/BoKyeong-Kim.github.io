---
layout: post
title: Chapter 6. Monte Carlo Simulation
subtitle: < [MIT] 데이터 사이언스 기초 >
feature-img: "assets/img/sample_feature_img_2.png"
categories : [Data/Science]
tags: [Data, Science, MIT, study]
---

- 몬테 카를로 시뮬레이션(Monte Carlo Simulation)
- 큰 수의 법칙
- 도박사의 오류
- 평균으로의 회귀
- 분산과 표준편차
- 확률 분포

<br>

[Chapter 6. Monte Carlo Simulation](https://www.edwith.org/datascience/lecture/33893/) 강의를 듣고 정리한 내용입니다.

<br>


---

몬테 카를로 시뮬레이션(Monte Carlo Simulation)

- 추리통계학을 이용해 알 수 없는 값을 추정하는 방법
- 핵심 개념은 모집단
    - 모집단 : 가능한 예시들의 전체 집합
    - 모집단으로부터 적당한 부분 집합을 뽑음
        - 표본의 통계를 통해 모집단을 추론
        - 일반적으로 모집단은 매우 큰 집단이고 표본은 그것보다 작은 집단
        - 무작위로 표본을 추출하면 그 표본이 모집단과 동일한 특성을 갖는 경향이 있음
        - 우리가 취할 수 있는 수많은 랜덤위크, 만개를 보지않고 100개를 추출해서 평균 계산한 후 기대값 계산
        - **표본 추출이 무작위어야함(난수 발생) - 무작위로 뽑은 표본이 아니면 모집단과 같은 특성을 가질 것이라고 기대할 수 있는 근거가 없음**

<br>

```python
class FairRoulette() :
	def __init__(self):
		self.pockets = []
		for i in range(1,37):
			self.pockets.append(i)
		self.ball = None
		self.pocketsOdds = len(self.pockets) - 1 #배당률계산
	
	def spin(self):
		self.ball = random.choice(self.pockets)
	
	def betPocket(self, pockets, amt): #배팅금액, 배팅포켓 선택
		if str(pocket) == str(self.ball):
			return amt * self.pocketOdds
		else :
			return -amt

	def __str__(self):
		return 'Fair Roulette'

	def playRoulette(game, numSpins, pocket, bet):
		totPocket = 0
		for i in range(numSpins):
			game.spin()
			totPocket += game.betPocket(pocket, bet)
		if toPrint:
			print(numSpins, 'spins of', game)
			print('Expected return betting', pocket, '=',\
						str(100*totPocket/numSpins) + '%\n')
		return (totPocket/numSpins)

game = FairRoulette()
for numSpins in (100, 1000000):
	for i in range(3):
			print(game, numSpins, 2, 1, True)
```

<br>

큰 수의 법칙 (또는 베르누이의 법칙)

- 실제 확률이 동일한 독립사건이 반복되면 실행횟수가 무한대로 갈수록 p와 다른 결과가 나오는 횟수와 비율이 0으로 수렴
- 공정한 룰렛 휠을 무한번 돌리면 기대값이 0이 됨

<br>

도박사의 오류

- 잘못된 결과의 오류
- 도박사의 오류에 의하면 사람들은 기대와 다른 이변이 일어나면 미래에 다시 정상으로 돌아올 것이라고 믿음
- 서로 영향을 끼치지 않는 일련의 확률적 사건들에서 상관관계를 찾는 오류를 발생

<br>

평균으로의 회귀

- 부모가 둘 다 평균보다 키크면 자식이 부모보다 작을 가능성이 높다
- 역으로 부모가 평균보다 작으면 자식은 평균보다 클 가능성이 높다.
- 도박사의 오류와 미묘하게 다름
- 극단적인 사건 다음에 오는 사건은 덜 극단적인 경향이 있다
- 공정 룰렛 휠을 10번 돌려 빨간색이 나온다면(극단적 사례) 10번에서는 빨간색이 10보다 적게 나온다는 개념(덜 극단적인 사건)
- 극단적인 결과보다는 20번 돌린 것의 평균 결과가 50% 빨간색이라는 평균값에 더 가까울 것
- 더 많은 표본을 취할수록 평균에 더 가까워짐

<br>

분산과 표준편차

- 기저확률의 변이성에 따라 필요한 표본의 수가 달라짐
- 데이터의 변이성을 알기위해 알아야되는 개념 : 분산
    - 평균으로부터 모두의 거리를 구하여 단순히 더함
    - 마지막으로 집합의 크기(전체 항목)개수로 나눔
    - 단지 항목의 개수가 많다는 이유로 분산이 높아지는것을 막기 위해서 항목의 개수로 정규화함
    - 제곱을 하는 이유
        - 차이가 양수, 음수 상관이 없다는 것 → 평균으로부터 어느 쪽에 있는지보다 근처에 있지않다는 것이 더 중요함
        - 거리를 제곱해 이상치를 특별히 강조
- 표준편차
    - 분산의 제곱근
    - 표준편차는 그 자체로는 의미가 없음 → 항상 평균을 고려해서 생각해야함
- 신뢰구간
    - 우리는 종종 평균만 가지고 예측하려함
    - 값을 모르는 매개변수를 설명할 떄 기댓값과 같은 특정 값을 주는 것보단 신뢰구간으로 표현하는 것이 좋음
    - 신뢰구간은 모르는값이 포함될 가능성이 높은 구간과 그 구간에 존재할 확률을 알려줌
    - 결과가 -1%와 +1% 사이일것이라 예측하고 전체게임중 95%는 이 예측이 맞을것이라고 기대하는 것
- 신뢰구간은 어떻게 계산할까?
    - 경험적인 규칙을 사용
    - 데이터를 얻어 평균을 찾고  표준편차를 계산하면 데이터의 58%는 평균값 앞뒤로 1 표준편차 범위 이내에 있음
- 경험적인 규칙을 적용하기위한 과정
    - 평균 추정 오차가 0
        - 높게 예측할 가능성과 낮게 예측할 가능성이 같아야함
        - 이런류의 실험과 시뮬레이션에선 타당한 가정
        - 오차에 편항이 없다는 가정
    - 오차의 분표가 정규분포
        - 가우스 분포, 정규분포
    - 이 두 가정하에 경험적 규칙은 항상 유효

<br>

확률분포

- 확률변수가 서로 다른값을 가지는 상대적 빈도를 나타내는 개념
- 이산확률변수
    - 유한 집합의 값들을 가짐
    - 동전을 던지면 앞면과 뒷면이란 2개의 값만 나옴
- 연속확률변수
    - 확률밀도함수(PDF) 사용
    - 두 값 사이 어딘가에 존재할 확률을 알려줌


----

<br>

다음강의 : Chapter 7. Confidence Intervals